{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1U56nC3nfuNfv_yXjgbJVWqTeU_in9GS-",
      "authorship_tag": "ABX9TyNCCo/yDUU24vHn2aXuY2e6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reema-dass26/Electricity_utilization_data_management/blob/dev/mqtt_data_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8R7HHzyPTSH",
        "outputId": "004a5c95-4e3c-4991-fdb5-457e88f982df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "import argparse\n",
        "# Setup argparse to accept command line arguments\n",
        "file_path = input(\"Please enter the path to your Excel file: \")\n",
        "\n",
        "# Load the Excel file without headers\n",
        "try:\n",
        "    df = pd.read_excel(file_path, header=None)\n",
        "    print(\"Excel file loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading the Excel file: {e}\")\n",
        "    exit()\n",
        "\n",
        "interval_of_logging=15\n",
        "# Step 1: Find the index of the row where the 'Spaltensumme' starts\n",
        "start_row_index = df[df[0] == 'Spaltensumme / minimale Qualität'].index[0]\n",
        "\n",
        "# Step 2: Extract rows starting from the next row after the marker, and reset index\n",
        "df_cleaned = df.iloc[start_row_index + 1:].reset_index(drop=True)\n",
        "\n",
        "# Step 3: Select only the first two columns (timestamps and corresponding values)\n",
        "df_cleaned = df_cleaned[[0, 1]]\n",
        "\n",
        "# Step 4: Rename the columns as per voltaware.\n",
        "df_cleaned.columns = ['timestampUtcEpochSecs', 'consumptionKwh']\n",
        "print(type(df_cleaned ['timestampUtcEpochSecs']))\n",
        "#validating the total consumption( for internal testing)\n",
        "total_sum = df_cleaned['consumptionKwh'].sum()\n",
        "print(f\"Sum of the 'consumptionKwh' column: {total_sum}\")\n",
        "\n",
        "#uuid generation for device id\n",
        "myuuid = uuid.uuid4()\n",
        "print('Your UUID is: ' + str(myuuid))\n",
        "\n",
        "# Cleaned values (convert timestampUtcEpochSecs to a list of integers) and convert the structure to list of objects\n",
        "cleaned_values = df_cleaned[['timestampUtcEpochSecs', 'consumptionKwh']].apply(lambda row: {\n",
        "    'timestampUtcEpochSecs': int(row['timestampUtcEpochSecs'].timestamp()),  # Convert Unix timestamp to integer\n",
        "    'consumptionKwh': row['consumptionKwh']\n",
        "}, axis=1).tolist()\n",
        "\n",
        "\n",
        "new_data = {\n",
        "  \t'deviceId' : str(myuuid),\n",
        "    'dataFrequencyMins' :interval_of_logging,\n",
        "    'date' :  str(datetime.now().strftime('%Y-%m-%d')),\n",
        "    \"electricReadings\": cleaned_values\n",
        "}\n",
        "\n",
        "# Define the output file path\n",
        "output_file_path = str(myuuid)\n",
        "\n",
        "with open(output_file_path, 'w') as f:\n",
        "    json.dump(new_data, f, indent=4)\n",
        "\n",
        "print(f\"New JSON file created: {output_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5bJmqoBPTYX",
        "outputId": "6f8d2ad0-1475-4e27-bb3b-fe33b049e6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the path to your Excel file: /content/sample_data/Report_20241211_20241214_202501101235.xlsx\n",
            "Excel file loaded successfully.\n",
            "<class 'pandas.core.series.Series'>\n",
            "Sum of the 'consumptionKwh' column: 0.08200000000000003\n",
            "Your UUID is: e81874d3-04a5-4c6b-9a86-0410accb4af6\n",
            "New JSON file created: e81874d3-04a5-4c6b-9a86-0410accb4af6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import uuid\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# User input for Excel file path\n",
        "file_path = input(\"Please enter the path to your Excel file: \")\n",
        "\n",
        "# Load the Excel file without headers\n",
        "try:\n",
        "    df = pd.read_excel(file_path, header=None)\n",
        "    print(\"Excel file loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading the Excel file: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Logging interval in minutes\n",
        "interval_of_logging = 15\n",
        "\n",
        "# Step 1: Find the index of the row where the 'Spaltensumme' starts\n",
        "start_row_index = df[df[0] == 'Spaltensumme / minimale Qualität'].index[0]\n",
        "\n",
        "# Step 2: Extract rows starting from the next row after the marker, and reset index\n",
        "df_cleaned = df.iloc[start_row_index + 1:].reset_index(drop=True)\n",
        "\n",
        "# Step 3: Select only the first two columns (timestamps and corresponding values)\n",
        "df_cleaned = df_cleaned[[0, 1]]\n",
        "\n",
        "# Step 4: Rename columns\n",
        "df_cleaned.columns = ['timestampUtcEpochSecs', 'consumptionKwh']\n",
        "\n",
        "# Convert timestamps to integers\n",
        "df_cleaned['timestampUtcEpochSecs'] = pd.to_datetime(df_cleaned['timestampUtcEpochSecs'])\n",
        "df_cleaned['timestampUtcEpochSecs'] = df_cleaned['timestampUtcEpochSecs'].astype(int) // 10**9  # Convert to Unix timestamp\n",
        "\n",
        "# Validate total consumption (for internal testing)\n",
        "total_sum = df_cleaned['consumptionKwh'].sum()\n",
        "print(f\"Sum of 'consumptionKwh' column: {total_sum}\")\n",
        "\n",
        "# Split the data into chunks of 96 records\n",
        "num_records_per_file = 96\n",
        "num_files = (len(df_cleaned) + num_records_per_file - 1) // num_records_per_file  # Round up division\n",
        "print(num_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYX9qGqBTbwT",
        "outputId": "7ed69684-ec69-4335-a511-76b9fc3e4aac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the path to your Excel file: /content/Report_20240128_20250128_202501281400.xlsx\n",
            "Excel file loaded successfully.\n",
            "Sum of 'consumptionKwh' column: 162.59400000000008\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter=0\n",
        "myuuid = uuid.uuid4()\n",
        "for i in range(num_files):\n",
        "    chunk = df_cleaned.iloc[i * num_records_per_file: (i + 1) * num_records_per_file]\n",
        "\n",
        "    # Convert to list of dictionaries\n",
        "    cleaned_values = chunk.to_dict(orient='records')\n",
        "\n",
        "    # Generate UUID for each file\n",
        "\n",
        "\n",
        "    # Prepare data dictionary\n",
        "    new_data = {\n",
        "        'deviceId': str(myuuid),\n",
        "        'dataFrequencyMins': interval_of_logging,\n",
        "        'date': str(datetime.now().strftime('%Y-%m-%d')),\n",
        "        \"electricReadings\": cleaned_values\n",
        "    }\n",
        "\n",
        "    # Define CSV file path\n",
        "    output_file_path = f\"{myuuid}_{counter}.csv\"\n",
        "    counter+=1\n",
        "\n",
        "   # Define file paths\n",
        "    output_csv_path = f\"{output_file_path}.csv\"\n",
        "    output_json_path = f\"{output_file_path}.json\"\n",
        "\n",
        "    # Save as CSV\n",
        "    chunk.to_csv(output_csv_path, index=False)\n",
        "\n",
        "    # Save as JSON\n",
        "    with open(output_json_path, 'w') as json_file:\n",
        "        json.dump(new_data, json_file, indent=4)\n",
        "\n",
        "    print(f\"New files created: {output_csv_path}, {output_json_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUyD05pbT2pF",
        "outputId": "cc92b601-3daa-4a1e-baf1-0ec5df25e65c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_0.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_0.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_1.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_1.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_2.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_2.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_3.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_3.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_4.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_4.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_5.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_5.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_6.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_6.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_7.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_7.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_8.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_8.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_9.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_9.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_10.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_10.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_11.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_11.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_12.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_12.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_13.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_13.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_14.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_14.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_15.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_15.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_16.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_16.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_17.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_17.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_18.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_18.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_19.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_19.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_20.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_20.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_21.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_21.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_22.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_22.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_23.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_23.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_24.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_24.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_25.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_25.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_26.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_26.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_27.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_27.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_28.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_28.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_29.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_29.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_30.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_30.csv.json\n",
            "New files created: 934c4422-75de-40c6-98f6-47e05562ca3f_31.csv.csv, 934c4422-75de-40c6-98f6-47e05562ca3f_31.csv.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "qKFI-p-hmmte"
      }
    }
  ]
}